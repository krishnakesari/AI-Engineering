{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Regression\n",
        "- Can we predict one variable based on other variables\n",
        "- Predict continous value\n",
        "- Dependent variable (Final goal or Y), Independent variable (target variables or X)\n",
        "\n",
        "## Applications\n",
        "- Sales forecasting\n",
        "- Satisfaction Analysis \n",
        "- Price estimation\n",
        "- Employment Income\n",
        "\n",
        "## Simple Regression\n",
        "  Using one variable to predict a value of other variable\n",
        "1. Simple Linear Regression\n",
        "2. Simple Non-linar Regression\n",
        "\n",
        "## Multiple Regression\n",
        "  Using more than one varaibles to predict a value of other variable\n",
        "1. Multiple Linear Regression\n",
        "2. Multiple Non-Linear Regression "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Simple Linear Regression\n",
        "- Predict Co2 emissions (Continuous value) using engize size, cylinders, fuel consumptiom\n",
        "- Dependent variable must have continuous values & Independent variables can have continuous\/discreet\/categorical values\n",
        "\n",
        "## Changes in one variable should explain other variable \n",
        "yhat = theta0 + theta1 * x1 \n",
        "1. yhat is response variable\n",
        "2. x1 is a single predictor\n",
        "3. theta0 is an intercept\n",
        "4. theta1 is slope\n",
        "5. theta0 and theta 1 are also called coefficients of linear equation\n",
        "\n",
        "## Finding line of best fit:\n",
        "- Most important part of Linear regression is to find theta0 and theta 1 \n",
        "- How we can adjust parameters to best fit theta ? \n",
        "### How to find best fit ?\n",
        "1. x1 = 5.4 ; independet variable y = 250 \n",
        "2. yhat = 340 (i.e. after applying yhat = theta0 + theta1 * x1)\n",
        "3. Find Residual Error:\n",
        "   - *Distance from data point to fitted regression line*\n",
        "   - Error = y - yhat = 250 - 340 = -90\n",
        "4. Find Mean Squared Error:\n",
        "   - *Mean of all Residual Errors shows how poorly the line fits with the dataset* \n",
        "   - MSE = 1\/n sigma (i = 1 -> n) (yi - yhati)^2\n",
        "\n",
        "#### Note: Objective of Linear Regression is to minimize the MSE equation \n",
        "\n",
        "### Mathematical Approach: \n",
        "1. calculate x bar (Avearge value of independent variable)\n",
        "2. calculate y bar (Average value of dependent variable)\n",
        "3. Plug x bar and y bar values in slope equation to find theta1\n",
        "4. Find intercept (theta0) based on slope (theta1), y, yhat\n",
        "#### Note: Theta0 is also called bias coefficient and Theta1 is coefficient for independent variable column\n",
        "\n",
        "### Advantage of Linear Regression\n",
        "   - Very Fast\n",
        "   - No Parameter Tuning Needed\n",
        "   - Easy to understand and highly interpretable "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Model Evaluation in Regression Models\n",
        "## Accuray of Model\n",
        "### Train and test on same dataset\n",
        "- Train set uses entire dataset and build a model\n",
        "- Test set includes a selected small portion of dataset without labels. (Note: Train set has labels but we should not use them )\n",
        "- Labels are used only for ground truthing\n",
        "- Labels are called \"Actual values of Test Set\" and the values predicted by Test set is called \"Predicted Values\"\n",
        "\n",
        "#### Measuring model accuracy\n",
        "- Difference between actual and predicted values\n",
        "Error = 1\/n sigma (j = 1 -> n) |yj - yhatj|\n",
        "\n",
        "##### Common Pitfalls to Note:\n",
        "- **High \"Training accuracy\"**\n",
        "  - Hight Training accuracy is not necessarily a good thing \n",
        "  - May result in over fitting \n",
        "    - Over fit: The model is overly trained to the dataset, which may capture noise and produce a non-generalized model\n",
        "- **Low \"out-of-sample accurary\"**\n",
        "  - It is important that our models have a high, out of sample accuracy (beacuse our goal is to predict values with high accuracy)\n",
        "  - How can we improve out-of-sample accuracy ? **use Train\/Test Split**\n",
        "\n",
        "### Train\/Test Split\n",
        "- Train set uses portion of dataset and build model\n",
        "- Test set uses other portion of dataset passed on to the model for prediction\n",
        "- Compared predicted values (from train set) with actual values (from test set)\n",
        "- **Mutually Exclusive**\n",
        "\n",
        "##### Note:\n",
        "- More accurate evalution on out-of-sample accuracy\n",
        "- Train your model with testing set afterwards as you don't want to loose potentially valuable data\n",
        "- Outcome of Train\/Test Split is highly dependent on which dataset the data is trained and tested\n",
        "\n",
        "### K-fold cross-validation\n",
        "- If k = 4 fold, we split up data set into \n",
        "- 1st fold - we use first 25% of dataset for testing and rest for training (Model build based on training set and evaluated using test set - accuracy is calculated)\n",
        "- 2nd fold - Second 25% data set is used for testing and rest for training (accurarcy calculated)\n",
        "- 3rd fold - third 25 %\n",
        "- 4th fold - fourth 25% \n",
        "\n",
        "#### Accuracy = average of all four model accuracies \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Evaluation Metrics in Regression Models\n",
        "- Used to explain performance of a model\n",
        "1. Mean Absolute Error (MAE) \n",
        "   - Mean of the absolute value of the error\n",
        "2. Mean Squared Error (MSE)\n",
        "   - Mean of the squared error\n",
        "   - Popular beacuse it focuses on large errors\n",
        "3. Root Mean Squared Error (RMSE)\n",
        "   - Sqare root of the mean squared error \n",
        "4. Relative Absolute Error (RAE)\n",
        "   - takes y bar value and normalizes error \n",
        "5. Relative Squared Error (RSE)\n",
        "   - Used for R-Squared value;  R^2 = (1 - RSE); R ^2 is a popular metric for measuring accuracy of the model\n",
        "   - R^2 shows how close the data values to the fitted regression line\n",
        "   - Higher R^2 means the better model fits the data\n",
        "  "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Multiple Linear Regression\n",
        "- Predicting Co2 emission based on engine and cylinder of all cars\n",
        "### Usage: \n",
        "1. To identify strength of the effect of independent variable have on dependent variable \n",
        "   - Eg: Does lecutre attendance and gender have any effect on exam performance of students ? \n",
        "2. To predict impacts of changes\n",
        "   - To identify how dependent variable changes when we change independent variables\n",
        "   - Eg: How a patient blood presure increase\/decrease for every unit increase\/ decrease in BMI (holding other factors constant)\n",
        "\n",
        "#### Note: \n",
        "1. In Multiple linear regression Independent variable (Y) is a linear combination of dependent variables (X)\n",
        "    - Yhat = theta0 + theta1 * Engine size + theta2 * Cylinders + .....\n",
        "2. You can identify \n",
        "   - which variable are significant to outcome variable\n",
        "   - how each feature impacts the outcome variable\n",
        "3. Predict unknown value \n",
        "\n",
        "### Mathematical Notation:\n",
        "- yhat = theta0 + theta1 * x1 + theta2 * x2 + ..... + theta n * xn \n",
        "- yhat = theta^T * X (.i.e. Theta Transposed X)\n",
        "  - n X 1 vector of unknown parameters in multidimensional space\n",
        "  - X is the vector of feature sets \n",
        "    - First value of the feature set is set to 1 to accomodate bias parameter theta0\n",
        "  - theta is the vector of coefficients (also called parameters \/ weight of regression equation)\n",
        "\n",
        "### Important Note:\n",
        "- Due to multiple dependent variable, we don't have a line anymore so we call it Plane \/ Hyperplane\n",
        "- Our goal is to find best fit hyper plane for data\n",
        "\n",
        "### How to find optimized parameters: \n",
        "- Optimized parameters would decrease the model error in hyperplance\n",
        "##### How it works ?\n",
        "- y (actual) = 196\n",
        "- yhat (predicted) = 140 \n",
        "- residual error = y - yhat = 196 - 140 = 56 \n",
        "\n",
        "### Errors:\n",
        "- Mean Squared Error (MSE): most popular\n",
        "   - how squared residual error is represented in the model\n",
        "   - Need to minimize MSE equation to best fit model\n",
        "     - Solution: Find best parameters (theta)\n",
        "\n",
        "#### How to estimate theta (parameter):\n",
        "1. Ordinary Least Squares:\n",
        "   - Tries to estimate the value of coefficients by minimizing mean square error\n",
        "   - Uses data as a matrix and applies linear algebra operations to estimate optimal values of theta\n",
        "   - **Downside:** It takes a very long time to perform matrix operations \n",
        "2. Optimization Approach:\n",
        "   - Iteratively minmizing error in the model\n",
        "   - Gradient Descent\n",
        "     - Starts optimization with random values for each coefficient \n",
        "     - Calculates error and tries to minimize error through changing value of coefficients in multiple iterations\n",
        "     - **Proper approach** for large datasets\n",
        "\n",
        "### Steps in prediction making:\n",
        "1. find parameters (Theta)\n",
        "2. Plug into the linear equation model (ytheta = inverse theta of X)\n",
        "- Eg. Co2 Emission = 125 + 6.2 Engine size + 14 Cylinders + ..... = 125 + 6.2 * 2.4 + 14 * 4 + ....  = 214.1\n",
        "\n",
        "### Caution:\n",
        "1. Adding too many independent variable will result in **overfitting** \n",
        "2. Should independent variables should be continuous\n",
        "   - Binary vairables (code categorical variables into numerical with dummy values eg: 0 for male and 1 for female)\n",
        "3. What are a linear relationships between dependent variable and independent variable ?\n",
        "   - use scatter plot to visually check the linearity \n",
        "   - If the relationship has no linearity use should use non-linear regression"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Non Linear Regression\n",
        "- If Scatter plot data shows a curvy line, linear regeression may not produce accurate predictions compared to non linear regression \n",
        "- There is a strong relationship between independent variable (GDP) and dependent variable (Year) but the relationship is non linear\n",
        "\n",
        "## What is non linear regression:\n",
        "- To model non-linear realationship between the dependent variable and a set of independent variables\n",
        "- yhat must be a non-linear function of the parameters theta, not necessarily the features x\n",
        "- It can be exponential, logistic etc. \n",
        "- Change of yhat depends on the changes in parameters theta\n",
        "\n",
        "### Note: \n",
        "- We Cannot use Ordinary Least Squares method to fit data \n",
        "- Estimation of parameters is not easy\n",
        "\n",
        "## estimation method: \n",
        "- Use exponential functions \n",
        "#### Polynomial Regressions\n",
        "- fits a curve line to data \n",
        "- Eg: Third degree polynomial equation (yhat = theta0 + theta1x + theta2 x^2 + theta3 x^3)\n",
        "- A polynomial regression model can be expressed\/transformed into linear regression model\n",
        "  - Eg: x1 = x, x2 = x^2, x3 = x^3 makes model into yhat = theta0 + theta1 x1 + theta2 x2 + theta3 x3\n",
        "1. Linear Regression\n",
        "2. Quadratic (parabolic) Regression\n",
        "3. Cubic Regression\n",
        "4. etc.............\n",
        "\n",
        "## How to determine if the problem is linear or non-linear \n",
        "- Inspect visually \n",
        "  - Calcuate correlation coefficients between independent and dependent variables if the value is 0.7 or higher there is a linear tendency\n",
        "- Based on accurarcy\n",
        "   - When we cannot accurately model with linear parameters\n",
        "\n",
        "## How should I model my data, if it displays non-linear on a scatter plot ?\n",
        "- Polynomial regression\n",
        "- Non-linear regression model\n",
        "- Transform your data"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Classification\n",
        "- Supervised learning model\n",
        "- Categorizing some unknown items into a discrete set of categories and \"classes\"\n",
        "- The target attribute is a categorical variable\n",
        "\n",
        "- Classification determines label for a test case\n",
        "  - Eg: 1.  loan default classification (Which customers will have problem repaying loans)\n",
        "    - Build a classifier \n",
        "    - pass data to model\n",
        "    - classify data into defaultor or not a defaultor (Binary classifier)\n",
        "  - Eg: 2. To predict a category where a customer belong\n",
        "  - Eg: 3. Churn detection: To predict if a customer switches to another product\/brand\n",
        "  - Eg: 4. Email \/ document classification\n",
        "\n",
        "## Types:\n",
        "- Binary classification\n",
        "- Multi-class classification \n",
        "\n",
        "## Algorithms\n",
        "1. Decision Trees (ID3, C4.5, C5.0)\n",
        "2. Naive Bayes\n",
        "3. Linear Discriminant Analysis\n",
        "4. k-Nearest Neighbor\n",
        "5. Logistic Regression\n",
        "6. Neural Networks\n",
        "7. Support Vector Machines (SVM)"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# k-Nearest Neighbors (KNN)\n",
        "- Given the labelled data, we need to predict the label of unknown case\n",
        "\n",
        "## Build a classifier\n",
        "- If Age and Income are predictors of customercategory \n",
        "\n",
        "### Note:\n",
        "  1. Poor Judgement: can we find closest cases and assign value to new case (1st nearest neighbor)\n",
        "  2. Good Judgement: Finding highest number of times a class appears in the neighborhood\n",
        "\n",
        "### Definition:\n",
        "- A method for classifying cases based on their similarity to other cases\n",
        "- Cases nearer to each other are \"neighbors\"\n",
        "- Distance between two cases is the measure of \"dissimilarity\"\/ \"similarity\"\n",
        "- Distance measured using Euclid distance\n",
        "\n",
        "### Usage:\n",
        "1. Pick a value for k\n",
        "2. Calculate the distance of unknown case from all cases\n",
        "3. Select the k-observations in the training data that are \"nearest\" to the unknown data point "
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}